"""
api.py
FastAPI ë°±ì—”ë“œ â€“ ê¸°ì¡´ RAG íŒŒì´í”„ë¼ì¸ì„ REST/SSE ì—”ë“œí¬ì¸íŠ¸ë¡œ ë…¸ì¶œí•©ë‹ˆë‹¤.

ì‹¤í–‰: python api.py
     (í˜¹ì€ uvicorn api:app --host 0.0.0.0 --port 8000 --reload)
"""

import os
import time
import json
import math
import asyncio
import logging
from typing import AsyncGenerator

import torch
from fastapi import FastAPI, HTTPException, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from contextlib import asynccontextmanager
from pydantic import BaseModel
from dotenv import load_dotenv

# â”€â”€ CUDA ìµœì í™” í”Œë˜ê·¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    torch.set_float32_matmul_precision("high")

from retriever import (
    load_embeddings,
    load_vector_db,
    load_reranker,
    build_bm25_retriever,
    get_ensemble_results,
    rerank_docs,
)
from external_pharma_api import fetch_external_pharma_docs, get_external_api_status
from generator import (
    build_context,
    generate_answer,
    verify_answer,
    self_correction_loop,
    get_query_optimizer,
    evaluate_with_ragas,
)
from processor import clear_gpu, get_gpu_status

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì•± ì‹œì‘ ì‹œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¦¬ì†ŒìŠ¤ ë¡œë“œ ë° ì¢…ë£Œ ì‹œ ì •ë¦¬."""
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = asyncio.get_event_loop()
    
    # ë¦¬ì†ŒìŠ¤ ë¹„ë™ê¸° ë¡œë“œ ì‹œì‘
    await loop.run_in_executor(None, _load_all_resources)
    
    yield
    
    # ì¢…ë£Œ ì‹œ í•„ìš”í•˜ë‹¤ë©´ ì •ë¦¬ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
    _resources.clear()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# App ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(title="ì•½ì‚¬ AI ì±—ë´‡ API", version="2.0", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€ ìƒìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DB_PATH = "./chroma_db_combined_1771477980"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OOS_GUARD_ENABLED = os.getenv("OOS_GUARD_ENABLED", "false").lower() in {"1", "true", "yes", "on"}
OOS_MIN_RELEVANCE = float(os.getenv("OOS_MIN_RELEVANCE", "0.55"))
OOS_MIN_TOP_SCORE = float(os.getenv("OOS_MIN_TOP_SCORE", "0.002"))
USE_QUERY_OPTIMIZER = os.getenv("USE_QUERY_OPTIMIZER", "false").lower() in {"1", "true", "yes", "on"}
VERIFY_MODEL = os.getenv("VERIFY_MODEL", "gpt-5.2")
RAGAS_MODEL = os.getenv("RAGAS_MODEL", "gpt-5.2")
USE_EXTERNAL_API = os.getenv("USE_EXTERNAL_API", "false").lower() in {"1", "true", "yes", "on"}
EXTERNAL_API_PROVIDER = os.getenv("EXTERNAL_API_PROVIDER", "openfda")
EXTERNAL_TOP_K = int(os.getenv("EXTERNAL_TOP_K", "4"))
EXTERNAL_TIMEOUT_SEC = float(os.getenv("EXTERNAL_TIMEOUT_SEC", "8"))
WEIGHT_EXTERNAL = float(os.getenv("WEIGHT_EXTERNAL", "0.2"))
EXTERNAL_FALLBACK_ONLY = os.getenv("EXTERNAL_FALLBACK_ONLY", "true").lower() in {"1", "true", "yes", "on"}
EXTERNAL_TRIGGER_MIN_RELEVANCE = float(os.getenv("EXTERNAL_TRIGGER_MIN_RELEVANCE", "0.55"))
EXTERNAL_TRIGGER_MIN_TOP_SCORE = float(os.getenv("EXTERNAL_TRIGGER_MIN_TOP_SCORE", "0.002"))
EXTERNAL_TRIGGER_MODE = os.getenv("EXTERNAL_TRIGGER_MODE", "or").strip().lower()  # or / and

# â”€â”€ ì „ì—­ ìƒíƒœ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_resources: dict = {}
_init_done = False
_init_logs: list[str] = []

def _log_init(msg: str):
    logger.info(msg)
    _init_logs.append(f"[{time.strftime('%H:%M:%S')}] {msg}")

def _load_all_resources():
    global _resources, _init_done
    if _init_done:
        return
    _log_init("ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
    _resources["embeddings"]     = load_embeddings()
    _log_init("ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    _resources["vector_db"]      = load_vector_db(DB_PATH)
    _log_init("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì™„ë£Œ")
    _resources["reranker"]       = load_reranker()
    _log_init("ë¦¬ë­ì»¤ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    _resources["bm25"], _resources["kiwi"] = build_bm25_retriever(DB_PATH)
    _log_init("BM25 ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    _resources["query_optimizer"] = get_query_optimizer(OPENAI_API_KEY) if USE_QUERY_OPTIMIZER else None
    _log_init("ì¿¼ë¦¬ ìµœì í™”ê¸° ì¤€ë¹„ ì™„ë£Œ" if USE_QUERY_OPTIMIZER else "ì¿¼ë¦¬ ìµœì í™”ê¸° ë¹„í™œì„±í™”(ì†ë„ ìš°ì„ )")
    _init_done = True
    _log_init("ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì¤€ë¹„ ì™„ë£Œ!")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìŠ¤í‚¤ë§ˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class ChatRequest(BaseModel):
    query: str
    model: str = "gpt-5"
    top_k: int = 5
    ensemble_k: int = 20
    weight_bm25: float = 0.8
    use_self_correction: bool = True


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Endpoints
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/health")
async def health():
    """ì„œë²„ ìƒíƒœ ë° GPU VRAM ì •ë³´."""
    gpu_info = {"available": False}
    if torch.cuda.is_available():
        gpu_info = get_gpu_status()
    return {
        "status": "ready" if _init_done else "initializing",
        "init_logs": _init_logs[-5:],
        "gpu": gpu_info,
        "external_api": get_external_api_status(EXTERNAL_API_PROVIDER),
    }


@app.post("/clear-memory")
async def clear_memory():
    """GPU ìºì‹œë¥¼ ê°•ì œë¡œ ë¹„ì›ë‹ˆë‹¤."""
    logger.info("GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ìš”ì²­ ìˆ˜ì‹ ")
    clear_gpu()
    return await health()


@app.get("/favicon.ico", include_in_schema=False)
async def favicon():
    """ë¸Œë¼ìš°ì €ì˜ ìë™ favicon ìš”ì²­ì— ëŒ€í•´ 204 No Contentë¡œ ì‘ë‹µí•˜ì—¬ ë¡œê·¸ë¥¼ ê¹”ë”í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤."""
    return Response(status_code=204)


@app.post("/chat")
async def chat_stream(req: ChatRequest):
    """SSE ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸."""
    if not _init_done:
        raise HTTPException(503, "ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    if not OPENAI_API_KEY:
        raise HTTPException(400, ".envì— OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

    async def generate() -> AsyncGenerator[str, None]:
        total_start = time.time()
        verify_task = None
        ragas_task = None
        search_elapsed = 0.0
        rerank_elapsed = 0.0
        gen_elapsed = 0.0
        verify_elapsed = 0.0
        ensemble_docs = []
        final_docs = []
        docs_payload: list[dict] = []
        external_docs_count = 0
        external_fallback_triggered = False
        external_trigger_reason: list[str] = []

        async def _cancel_pending_tasks():
            pending = [t for t in (verify_task, ragas_task) if t is not None and not t.done()]
            if pending:
                for t in pending:
                    t.cancel()
                await asyncio.gather(*pending, return_exceptions=True)

        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = asyncio.get_event_loop()

        def _sse(event: str, data: dict) -> str:
            return f"event: {event}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"

        def _external_diag() -> dict:
            try:
                return get_external_api_status(EXTERNAL_API_PROVIDER)
            except Exception:
                return {
                    "provider": EXTERNAL_API_PROVIDER,
                    "connected": None,
                    "message": "status_probe_failed",
                }

        try:
            # â”€â”€ 1. ì•™ìƒë¸” ê²€ìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            yield _sse("status", {"step": "ê²€ìƒ‰ ì¤‘...", "icon": "ğŸ”"})
            search_start = time.time()
            ensemble_docs = await loop.run_in_executor(
                None,
                lambda: get_ensemble_results(
                    query=req.query,
                    kiwi=_resources["kiwi"],
                    bm25_retriever=_resources["bm25"],
                    vector_db=_resources["vector_db"],
                    query_optimizer=_resources.get("query_optimizer"),
                    k=req.ensemble_k,
                    weight_bm25=req.weight_bm25,
                    weight_vector=round(1.0 - req.weight_bm25, 2),
                    use_external_api=bool(USE_EXTERNAL_API and not EXTERNAL_FALLBACK_ONLY),
                    external_provider=EXTERNAL_API_PROVIDER,
                    external_top_k=EXTERNAL_TOP_K,
                    external_timeout_sec=EXTERNAL_TIMEOUT_SEC,
                    weight_external=WEIGHT_EXTERNAL,
                ),
            )
            search_elapsed = time.time() - search_start

            # â”€â”€ 2. ë¦¬ë­í‚¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            yield _sse("status", {"step": f"{len(ensemble_docs)}ê°œ ë¬¸ì„œ ë¦¬ë­í‚¹ ì¤‘...", "icon": "âš¡"})
            rerank_start = time.time()
            ranked_pairs = await loop.run_in_executor(
                None,
                lambda: rerank_docs(
                    query=req.query,
                    docs=ensemble_docs,
                    reranker=_resources["reranker"],
                    top_k=req.top_k,
                    batch_size=64, # RTX 2070 8GB ìµœì  ë°°ì¹˜ ì‚¬ì´ì¦ˆ ìƒí–¥
                ),
            )
            rerank_elapsed = time.time() - rerank_start

            rerank_scores = [s for s, _ in ranked_pairs]
            final_docs    = [d for _, d in ranked_pairs]
            max_score     = max(rerank_scores) if rerank_scores else 1.0

            # â”€â”€ 2.5 ì™¸ë¶€ API Fallback ë™ì  ì°¸ì¡° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if USE_EXTERNAL_API and EXTERNAL_FALLBACK_ONLY:
                top_score_local = float(rerank_scores[0]) if rerank_scores else -999.0
                top_rel_local = 1.0 / (1.0 + math.exp(-max(min(top_score_local, 30.0), -30.0)))
                low_rel = top_rel_local < EXTERNAL_TRIGGER_MIN_RELEVANCE
                low_score = top_score_local < EXTERNAL_TRIGGER_MIN_TOP_SCORE
                if low_rel:
                    external_trigger_reason.append("low_relevance")
                if low_score:
                    external_trigger_reason.append("low_top_score")

                trigger_mode = EXTERNAL_TRIGGER_MODE if EXTERNAL_TRIGGER_MODE in {"or", "and"} else "or"
                should_call_external = (
                    (low_rel and low_score)
                    if trigger_mode == "and"
                    else (low_rel or low_score)
                )

                if should_call_external:
                    external_fallback_triggered = True
                    yield _sse("status", {"step": "ì™¸ë¶€ ì•½í•™ API ë³´ê°• ê²€ìƒ‰ ì¤‘...", "icon": "ğŸŒ"})
                    external_docs = await loop.run_in_executor(
                        None,
                        lambda: fetch_external_pharma_docs(
                            query=req.query,
                            provider=EXTERNAL_API_PROVIDER,
                            top_k=EXTERNAL_TOP_K,
                            timeout_sec=EXTERNAL_TIMEOUT_SEC,
                        ),
                    )
                    external_docs_count = len(external_docs)

                    if external_docs_count > 0:
                        # ë¡œì»¬ ê²€ìƒ‰ ê²°ê³¼ + ì™¸ë¶€ API ë¬¸ì„œë¥¼ í•©ì³ ì¬ë¦¬ë­í‚¹
                        merged_docs = ensemble_docs + external_docs
                        rerank_refine_start = time.time()
                        ranked_pairs = await loop.run_in_executor(
                            None,
                            lambda: rerank_docs(
                                query=req.query,
                                docs=merged_docs,
                                reranker=_resources["reranker"],
                                top_k=req.top_k,
                                batch_size=64,
                            ),
                        )
                        rerank_elapsed += (time.time() - rerank_refine_start)
                        rerank_scores = [s for s, _ in ranked_pairs]
                        final_docs = [d for _, d in ranked_pairs]
                        max_score = max(rerank_scores) if rerank_scores else 1.0
                        logger.info(
                            "[ExternalFallback] triggered=true, fetched=%d, top_score_local=%.4f, top_rel_local=%.4f",
                            external_docs_count,
                            top_score_local,
                            top_rel_local,
                        )
                else:
                    logger.info(
                        "[ExternalFallback] triggered=false, mode=%s, top_score_local=%.4f, top_rel_local=%.4f",
                        trigger_mode,
                        top_score_local,
                        top_rel_local,
                    )

            def _build_docs_payload() -> list[dict]:
                payload = []
                local_max_score = max(rerank_scores) if rerank_scores else 1.0
                for i, (score, doc) in enumerate(zip(rerank_scores, final_docs), 1):
                    pct = min(score / max(local_max_score, 1e-6), 1.0)
                    payload.append({
                        "rank": i,
                        "source": os.path.basename(doc.metadata.get("source", "Unknown")),
                        "score": round(float(score), 4),
                        "pct": round(float(pct) * 100, 1),
                        "preview": doc.page_content.replace("passage: ", "").replace("\n", " ")[:280],
                    })
                return payload

            # â”€â”€ 3. ì°¸ê³  ë¬¸ì„œ ì •ë³´ ì„ ì œì  ì „ì†¡ (UI ë¡œë”© ì²´ê° ê°œì„ ) â”€â”€â”€â”€â”€â”€
            docs_payload = _build_docs_payload()
            # (UIê°€ 'docs' ì´ë²¤íŠ¸ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤ë©´ ë¯¸ë¦¬ ë³´ëƒ„)
            yield _sse("docs", {"docs": docs_payload})

            # â”€â”€ 3.5 Out-of-scope ê°€ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            top_score = float(rerank_scores[0]) if rerank_scores else -999.0
            # CrossEncoder raw scoreë¥¼ 0~1 relevanceë¡œ ë§¤í•‘ (sigmoid)
            top_relevance = 1.0 / (1.0 + math.exp(-max(min(top_score, 30.0), -30.0)))

            # NOTE:
            # CrossEncoder raw score ë²”ìœ„ê°€ ì‘ê²Œ ë‚˜ì˜¤ëŠ” ë°ì´í„°ì…‹ì—ì„œëŠ”
            # sigmoid(top_score) ê¸°ë°˜ relevanceë§Œìœ¼ë¡œ in-scope ì§ˆë¬¸ì´ ê³¼ì°¨ë‹¨ë  ìˆ˜ ìˆìŒ.
            # ë”°ë¼ì„œ "relevance + raw top_score"ë¥¼ í•¨ê»˜ ë§Œì¡±í•  ë•Œë§Œ OOS ì°¨ë‹¨.
            should_oos_block = (
                OOS_GUARD_ENABLED
                and (top_relevance < OOS_MIN_RELEVANCE)
                and (top_score < OOS_MIN_TOP_SCORE)
            )

            # ìµœì¢… OOS ì§ì „, fallback ëª¨ë“œë¼ë©´ ì™¸ë¶€ APIë¥¼ 1íšŒ ê°•ì œ ë³´ê°• ì‹œë„
            if (
                should_oos_block
                and USE_EXTERNAL_API
                and EXTERNAL_FALLBACK_ONLY
                and external_docs_count == 0
            ):
                yield _sse("status", {"step": "ì™¸ë¶€ ì•½í•™ API ì¬ë³´ê°• ê²€ìƒ‰ ì¤‘...", "icon": "ğŸŒ"})
                external_fallback_triggered = True
                external_trigger_reason.append("pre_oos_force_fallback")
                external_docs = await loop.run_in_executor(
                    None,
                    lambda: fetch_external_pharma_docs(
                        query=req.query,
                        provider=EXTERNAL_API_PROVIDER,
                        top_k=EXTERNAL_TOP_K,
                        timeout_sec=EXTERNAL_TIMEOUT_SEC,
                    ),
                )
                external_docs_count = len(external_docs)

                if external_docs_count > 0:
                    merged_docs = ensemble_docs + external_docs
                    rerank_refine_start = time.time()
                    ranked_pairs = await loop.run_in_executor(
                        None,
                        lambda: rerank_docs(
                            query=req.query,
                            docs=merged_docs,
                            reranker=_resources["reranker"],
                            top_k=req.top_k,
                            batch_size=64,
                        ),
                    )
                    rerank_elapsed += (time.time() - rerank_refine_start)
                    rerank_scores = [s for s, _ in ranked_pairs]
                    final_docs = [d for _, d in ranked_pairs]
                    top_score = float(rerank_scores[0]) if rerank_scores else -999.0
                    top_relevance = 1.0 / (1.0 + math.exp(-max(min(top_score, 30.0), -30.0)))
                    should_oos_block = (
                        OOS_GUARD_ENABLED
                        and (top_relevance < OOS_MIN_RELEVANCE)
                        and (top_score < OOS_MIN_TOP_SCORE)
                    )
                    docs_payload = _build_docs_payload()
                    yield _sse("docs", {"docs": docs_payload})

            if should_oos_block:
                oos_answer = (
                    "ì œê³µëœ ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. "
                    "í˜„ì¬ ë³´ìœ í•œ ê·¼ê±° ë²”ìœ„ ë°– ì§ˆë¬¸ìœ¼ë¡œ íŒë‹¨ë˜ì–´ ì¶”ì¸¡ ë‹µë³€ì„ ìƒëµí•©ë‹ˆë‹¤. "
                    "ê´€ë ¨ ì˜ì•½í’ˆ/ì¦ìƒ í‚¤ì›Œë“œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ë‹¤ì‹œ í™•ì¸í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
                )
                total_elapsed_oos = time.time() - total_start
                yield _sse("done", {
                    "answer": oos_answer,
                    "is_pass": True,
                    "correction_rounds": 0,
                    "correction_logs": [],
                    "verify_result": (
                        f"OOS_GUARD (top_relevance={top_relevance:.3f}, rel_threshold={OOS_MIN_RELEVANCE:.3f}, "
                        f"top_score={top_score:.4f}, score_threshold={OOS_MIN_TOP_SCORE:.4f})"
                    ),
                    "metrics_pending": False,
                    "ragas": {"faithfulness": 0.0, "answer_relevancy": 0.0},
                    "docs": docs_payload,
                    "metrics": {
                        "search_s": round(search_elapsed, 3),
                        "rerank_s": round(rerank_elapsed, 3),
                        "gen_s": 0.0,
                        "verify_s": 0.0,
                        "total_s": round(total_elapsed_oos, 3),
                        "ensemble_n": len(ensemble_docs),
                        "final_n": len(final_docs),
                        "top_score": round(top_score, 4),
                        "top_relevance": round(top_relevance, 4),
                        "oos_min_top_score": round(OOS_MIN_TOP_SCORE, 4),
                        "external_fallback_enabled": bool(USE_EXTERNAL_API and EXTERNAL_FALLBACK_ONLY),
                        "external_fallback_triggered": external_fallback_triggered,
                        "external_docs_count": external_docs_count,
                        "external_trigger_reason": external_trigger_reason,
                        "external_api_status": _external_diag(),
                        "oos_guard": True,
                    },
                })
                return

            # â”€â”€ 4. ë‹µë³€ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            context_text = build_context(final_docs)
            yield _sse("status", {"step": "ë‹µë³€ ìƒì„± ì¤‘...", "icon": "âœï¸"})
            gen_start = time.time()
            
            initial_answer = ""
            # ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•´ async_mode=True ì‚¬ìš© ë° async for ë£¨í”„ ì ìš©
            async_stream = await generate_answer(
                query=req.query,
                context_text=context_text,
                openai_api_key=OPENAI_API_KEY,
                model=req.model,
                stream=True,
                async_mode=True,
            )
            
            async for chunk in async_stream:
                if chunk:
                    initial_answer += chunk
                    yield _sse("token", {"text": chunk})
            
            gen_elapsed = time.time() - gen_start

            # â”€â”€ 5. ê²€ì¦ ë° RAGAS í‰ê°€ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì§€ì—° ì‹œê°„ ë‹¨ì¶•) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            yield _sse("status", {"step": "í’ˆì§ˆ ê²€ì¦ ë° ì§€í‘œ ë¶„ì„ ì¤‘...", "icon": "âš¡"})
            
            # ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜ë“¤
            async def _run_verify():
                return await loop.run_in_executor(
                    None,
                    lambda: verify_answer(
                        query=req.query, context_text=context_text,
                        answer=initial_answer, openai_api_key=OPENAI_API_KEY, model=VERIFY_MODEL
                    )
                )

            async def _run_ragas():
                if req.model == "debug":
                    return {"faithfulness": 0.0, "answer_relevancy": 0.0}
                return await loop.run_in_executor(
                    None,
                    lambda: evaluate_with_ragas(
                        query=req.query,
                        answer=initial_answer,
                        final_docs=final_docs,
                        embeddings=_resources["embeddings"],
                        openai_api_key=OPENAI_API_KEY,
                        eval_model=RAGAS_MODEL,
                    )
                )

            # ê²€ì¦ê³¼ RAGASë¥¼ ë™ì‹œì— ì‹œì‘
            verify_task = asyncio.create_task(_run_verify())
            ragas_task = asyncio.create_task(_run_ragas())

            # ê²€ì¦ ê²°ê³¼ëŠ” êµì • ë£¨í”„ ì§„ì… ì—¬ë¶€ë¥¼ ê²°ì •í•˜ë¯€ë¡œ ë¨¼ì € ê¸°ë‹¤ë¦¼ (í•˜ì§€ë§Œ RAGASëŠ” ê³„ì† ëŒì•„ê°)
            verify_result = await verify_task
            verify_elapsed = time.time() - gen_start - gen_elapsed # ëŒ€ëµì ì¸ ì‹œê°„

            final_answer = initial_answer
            correction_rounds = 0
            correction_logs: list[dict] = []
            
            # ê²€ì¦ ê²°ê³¼ ì¦‰ì‹œ ì „ì†¡ (UI ë°˜ì˜ìš©)
            yield _sse("verdict", {
                "is_pass": "PASS" in verify_result.upper(),
                "verify_result": verify_result
            })

            if req.use_self_correction and "FAIL" in verify_result.upper():
                yield _sse("status", {"step": "ìë™ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹œì‘...", "icon": "ğŸ¤–"})
                
                # êµì • ë£¨í”„ ì§„ì… ì „, ì´ì „ RAGAS íƒœìŠ¤í¬ê°€ ìˆë‹¤ë©´ ì·¨ì†Œí•˜ê±°ë‚˜ ë¬´ì‹œ (ìƒˆë¡œìš´ ë‹µë³€ìœ¼ë¡œ í‰ê°€í•  ê²ƒì´ë¯€ë¡œ)
                if ragas_task and not ragas_task.done():
                    ragas_task.cancel()

                # ë¹„ë™ê¸° ì œë„ˆë ˆì´í„°ë¡œ êµì • ë£¨í”„ ì‹¤í–‰
                async for event_type, value in self_correction_loop(
                    query=req.query,
                    context_text=context_text,
                    initial_answer=initial_answer,
                    initial_verify_result=verify_result,
                    openai_api_key=OPENAI_API_KEY,
                    gen_model=req.model,
                    max_rounds=1, # 1íšŒ ê¶Œì¥
                    initial_ragas_result=None, # ì§€í‘œ ìƒëµ
                    embeddings=_resources["embeddings"],
                    final_docs=final_docs,
                ):
                    if event_type == "status":
                        yield _sse("status", value)
                    elif event_type == "token":
                        yield _sse("token", {"text": value})
                    elif event_type == "done_loop":
                        final_answer = value["answer"]
                        verify_result = value["verify_result"]
                        correction_rounds = value["rounds"]
                        correction_logs = value["logs"]
                
                # êµì • í›„ ì¦‰ì‹œ 'done' ì „ì†¡ (RAGASëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‹œì‘)
                yield _sse("status", {"step": "êµì • ì™„ë£Œ!", "icon": "âœ…"})
                total_elapsed = time.time() - total_start
                
                # êµì •ëœ ë‹µë³€ì— ëŒ€í•´ RAGAS ë‹¤ì‹œ ì‹œì‘
                ragas_task = asyncio.create_task(_run_ragas_for_answer(final_answer))

                yield _sse("done", {
                    "answer": final_answer,
                    "is_pass": "PASS" in verify_result.upper(),
                    "correction_rounds": correction_rounds,
                    "correction_logs": correction_logs,
                    "verify_result": verify_result,
                    "metrics_pending": True,
                    "ragas": {"faithfulness": 0.0, "answer_relevancy": 0.0},
                    "docs": docs_payload,
                    "metrics": {
                        "search_s": round(search_elapsed, 3),
                        "rerank_s": round(rerank_elapsed, 3),
                        "gen_s": round(gen_elapsed, 3),
                        "verify_s": round(verify_elapsed, 3),
                        "total_s": round(total_elapsed, 3),
                        "ensemble_n": len(ensemble_docs),
                        "final_n": len(final_docs),
                        "external_fallback_enabled": bool(USE_EXTERNAL_API and EXTERNAL_FALLBACK_ONLY),
                        "external_fallback_triggered": external_fallback_triggered,
                        "external_docs_count": external_docs_count,
                        "external_trigger_reason": external_trigger_reason,
                        "external_api_status": _external_diag(),
                    },
                })
            else:
                # PASSì¸ ê²½ìš° ì¦‰ì‹œ 'done'ì„ ë³´ë‚´ì–´ ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”
                yield _sse("status", {"step": "ê²€ì¦ ì™„ë£Œ!", "icon": "âœ…"})
                total_elapsed_partial = time.time() - total_start
                yield _sse("done", {
                    "answer": final_answer,
                    "is_pass": True,
                    "correction_rounds": 0,
                    "correction_logs": [],
                    "verify_result": verify_result,
                    "metrics_pending": True,
                    "ragas": {"faithfulness": 0.0, "answer_relevancy": 0.0},
                    "docs": docs_payload,
                    "metrics": {
                        "search_s": round(search_elapsed, 3),
                        "rerank_s": round(rerank_elapsed, 3),
                        "gen_s": round(gen_elapsed, 3),
                        "verify_s": round(verify_elapsed, 3),
                        "total_s": round(total_elapsed_partial, 3),
                        "ensemble_n": len(ensemble_docs),
                        "final_n": len(final_docs),
                        "external_fallback_enabled": bool(USE_EXTERNAL_API and EXTERNAL_FALLBACK_ONLY),
                        "external_fallback_triggered": external_fallback_triggered,
                        "external_docs_count": external_docs_count,
                        "external_trigger_reason": external_trigger_reason,
                        "external_api_status": _external_diag(),
                    },
                })
            
            # â”€â”€ 6. ê³µí†µ RAGAS ì—…ë°ì´íŠ¸ (ë°±ê·¸ë¼ìš´ë“œ ì™„ë£Œ ëŒ€ê¸°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if ragas_task:
                try:
                    ragas_results = await ragas_task
                    yield _sse("metrics_update", ragas_results)
                except Exception as ragas_err:
                    logger.warning("RAGAS evaluation failed: %s", ragas_err)

        except asyncio.CancelledError:
            logger.info("Chat stream cancelled by client.")
            await _cancel_pending_tasks()
            return
        except Exception as e:
            logger.exception("Chat error: %s", e)
            total_elapsed_error = time.time() - total_start
            try:
                yield _sse("done", {
                    "answer": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "is_pass": False,
                    "correction_rounds": 0,
                    "correction_logs": [],
                    "verify_result": f"ERROR: {str(e)}",
                    "metrics_pending": False,
                    "ragas": {"faithfulness": 0.0, "answer_relevancy": 0.0},
                    "docs": docs_payload,
                    "metrics": {
                        "search_s": round(search_elapsed, 3),
                        "rerank_s": round(rerank_elapsed, 3),
                        "gen_s": round(gen_elapsed, 3),
                        "verify_s": round(verify_elapsed, 3),
                        "total_s": round(total_elapsed_error, 3),
                        "ensemble_n": len(ensemble_docs),
                        "final_n": len(final_docs),
                        "external_fallback_enabled": bool(USE_EXTERNAL_API and EXTERNAL_FALLBACK_ONLY),
                        "external_fallback_triggered": external_fallback_triggered,
                        "external_docs_count": external_docs_count,
                        "external_trigger_reason": external_trigger_reason,
                        "external_api_status": _external_diag(),
                        "error": True,
                    },
                })
            except Exception:
                pass
        finally:
            await _cancel_pending_tasks()

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
        },
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Static files (í”„ë¡ íŠ¸ì—”ë“œ ì„œë¹™)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STATIC_DIR = os.path.join(os.path.dirname(__file__), "web-ui")
if os.path.exists(STATIC_DIR):
    app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

    @app.get("/")
    async def serve_index():
        return FileResponse(os.path.join(STATIC_DIR, "index.html"))


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì§ì ‘ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api:app", host="0.0.0.0", port=8000, reload=False)
